input {
    kafka {
        bootstrap_servers => "kafka-1:19092,kafka-2:29092,kafka-3:39092"
        topics => ["mysql_merchant"]
        codec => "json"
        consumer_threads => 3
        group_id => "mysql_merchant"
        decorate_events => true
        auto_offset_reset => "latest"
    }
}

filter {
    if [latest_updated_date] {
        date {
            match => ["latest_updated_date", "yyyy-MM-dd HH:mm:ss", "ISO8601"]
            add_field => {"updated_date" => "%{+YYYY-MM-dd}"}
            add_field => {"updated_hour" => "%{+HH}"}
        }
    } else if [updated_at] {
        date {
            match => ["updated_at", "yyyy-MM-dd HH:mm:ss", "ISO8601"]
            add_field => {"updated_date" => "%{+YYYY-MM-dd}"}
            add_field => {"updated_hour" => "%{+HH}"}
        }
    } else if [created_at] {
        date {
            match => ["created_at", "yyyy-MM-dd HH:mm:ss", "ISO8601"]
            add_field => {"updated_date" => "%{+YYYY-MM-dd}"}
            add_field => {"updated_hour" => "%{+HH}"}
        }
    } else {
        date {
            match => ["@timestamp", "ISO8601"]
            add_field => {"updated_date" => "%{+YYYY-MM-dd}"}
            add_field => {"updated_hour" => "%{+HH}"}
        }
    }
}

output {
      if [@metadata][kafka][topic] == "mysql_merchant" {
          webhdfs {
              host => "10.1.1.151"
              port => 50070
              codec => "json"
              idle_flush_time => 10
              retry_interval => 0.5
              flush_size => 500
              compression => "snappy"
              path => "/user/hadoop/logstash/mysql/merchant/%{updated_date}/%{updated_hour}"
              user => "hadoop"
          }
      }
}