input {
    kafka {
        bootstrap_servers => "kafka-1:19092,kafka-2:29092,kafka-3:39092"
        topics => ["es_example"]
        codec => "json"
        consumer_threads => 1
        group_id => "es_example"
        decorate_events => true
        auto_offset_reset => "latest" # Change this to "latest" when deploy to production
    }
}

filter {
    if [createdDate] {
        date {
            match => ["createdDate", "yyyy-MM-dd HH:mm:ss", "ISO8601", "UNIX_MS"]
            add_field => {"updated_date" => "%{+YYYY-MM-dd}"}
            add_field => {"updated_hour" => "%{+HH}"}
        }
    } else {
        date {
            match => ["@timestamp", "ISO8601"]
            add_field => {"updated_date" => "%{+YYYY-MM-dd}"}
            add_field => {"updated_hour" => "%{+HH}"}
        }
    }
}

output {
      if [@metadata][kafka][topic] == "es_example" {
          webhdfs {
              host => "nodemaster_host"
              port => 50070
              codec => "json"
              idle_flush_time => 10
              retry_interval => 0.5
              flush_size => 500
              compression => "snappy"
              path => "/user/hadoop/logstash/es/example/%{updated_date}/%{updated_hour}"
              user => "hadoop"
              retry_times => 10
          }
      }
}